{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3696694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import tifffile as tiff      # pip install tifffile\n",
    "import numpy as np\n",
    "\n",
    "class FlameSeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns (seq_len, 1, H, W) tensor of float32 temperatures (°C) and a label.\n",
    "    Label is 1 for 'Fire', 0 for 'No Fire'.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, seq_len=5, downscale=1.0, transform=None):\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        root = Path(root)\n",
    "        for cls_name in [\"Fire\", \"No Fire\"]:\n",
    "            label = 1 if cls_name == \"Fire\" else 0\n",
    "            tiff_dir = root / cls_name / \"Thermal\" / \"Celsius TIFF\"\n",
    "            paths = sorted(tiff_dir.glob(\"*.TIFF\"))\n",
    "            # sliding window\n",
    "            for i in range(len(paths) - seq_len + 1):\n",
    "                self.samples.append((paths[i:i + seq_len], label))\n",
    "\n",
    "        self.downscale = downscale     # e.g. 0.5 to halve width and height\n",
    "\n",
    "    def _read_tiff(self, path):\n",
    "        arr = tiff.imread(str(path)).astype(np.float32)     # shape (H, W)\n",
    "        if self.downscale != 1.0:\n",
    "            # cheap shrink to cut memory, keep it simple\n",
    "            h, w = arr.shape\n",
    "            arr = arr[:: int(1 / self.downscale), :: int(1 / self.downscale)]\n",
    "        # add channel axis\n",
    "        arr = torch.from_numpy(arr)[None]    # (1, H, W)\n",
    "        # simple 0-1 scaling; adapt if sensor limits differ\n",
    "        arr = (arr - 0.0) / 1000.0\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths, label = self.samples[idx]\n",
    "        frames = [self._read_tiff(p) for p in paths]\n",
    "        seq = torch.stack(frames)            # (seq_len, 1, H, W)\n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "        return seq, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CNN encoder — keep it tiny so LSTM sees small vectors.\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):                    # (B, 1, H, W)\n",
    "        x = self.conv(x)                     # (B, 64, 1, 1)\n",
    "        return x.view(x.size(0), -1)         # (B, 64)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden=128):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder()\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=hidden,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x):                    # (B, T, 1, H, W)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B * T, C, H, W)\n",
    "        feats = self.encoder(x)              # (B*T, 64)\n",
    "        feats = feats.view(B, T, -1)         # (B, T, 64)\n",
    "        lstm_out, _ = self.lstm(feats)\n",
    "        logits = self.fc(lstm_out[:, -1])    # last timestep\n",
    "        return logits.squeeze(1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    root = \"CVSubset/FLAME 3 CV Dataset (Sycan Marsh)\"\n",
    "    dataset = FlameSeqDataset(root, seq_len=5)\n",
    "    loader = DataLoader(dataset, batch_size=8, shuffle=True,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = CNNLSTM()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        for seq, label in loader:\n",
    "            optimiser.zero_grad()\n",
    "            logit = model(seq)\n",
    "            loss = criterion(logit, label)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        print(f\"epoch {epoch} loss {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
